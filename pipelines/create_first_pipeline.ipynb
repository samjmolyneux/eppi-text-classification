{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGIN\n",
    "# Handle to the workspace\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"56539498-d3d8-4a3b-92f4-f3b098a11d1e\",\n",
    "    resource_group_name=\"continuous_review_ms_and_ucl\",\n",
    "    workspace_name=\"EPPI_DEV\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve an existing environment from the workspace\n",
    "env_name = \"aml-eppi-text-classification\"\n",
    "env_version = \"0.1.3\"  # Specify the version of the environment\n",
    "pipeline_job_env = ml_client.environments.get(name=env_name, version=env_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "\n",
    "data_path = \"../data/raw/debunking_review.tsv\"\n",
    "\n",
    "debunking_data = Data(\n",
    "    name=\"debunking_review_data\",\n",
    "    path=data_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"Dataset for testing sams text classification pipeline\",\n",
    "    version=\"1.0.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debunking_data = ml_client.data.create_or_update(debunking_data)\n",
    "print(\n",
    "    f\"Dataset with name {debunking_data.name} was registered to workspace, the dataset version is {debunking_data.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dependencies_dir = \"./dependencies\"\n",
    "os.makedirs(dependencies_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./dependencies/conda.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {dependencies_dir}/conda.yaml\n",
    "name: eppi-text-classification-env \n",
    "channels:\n",
    "  - conda-forge \n",
    "dependencies:\n",
    "  - python=3.11.8\n",
    "  - pip=24.0\n",
    "  - pip:\n",
    "    - git+https://github.com/samjmolyneux/eppi-text-classification.git@dev\n",
    "    - https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name aml-eppi-text-classification is registered to workspace, the environment version is 0.1.3\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "custom_env_name = \"aml-eppi-text-classification\"\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"Custom environment for eppi classifier workbench pipeline\",\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yaml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    "    version=\"0.1.3\",\n",
    ")\n",
    "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./dependencies/display_image_env.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {dependencies_dir}/display_image_env.yaml\n",
    "name: display-image-env \n",
    "channels:\n",
    "  - conda-forge \n",
    "dependencies:\n",
    "  - python=3.11.8\n",
    "  - pip=24.0\n",
    "  - pip:\n",
    "    - azureml-mlflow==1.42.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name display-image-env is registered to workspace, the environment version is 0.1.0\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "custom_env_name = \"display-image-env\"\n",
    "\n",
    "display_image_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"Environment for displaying images in azure ml\",\n",
    "    conda_file=os.path.join(dependencies_dir, \"display_image_env.yaml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    "    version=\"0.1.0\",\n",
    ")\n",
    "display_image_env = ml_client.environments.create_or_update(display_image_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {display_image_env.name} is registered to workspace, the environment version is {display_image_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data component\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "process_data = \"./components/process_data\"\n",
    "os.makedirs(process_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/process_data/data_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {process_data}/data_prep.py\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import save_npz\n",
    "\n",
    "from eppi_text_classification import (\n",
    "    get_features_and_labels,\n",
    "    get_tfidf_and_names,\n",
    ")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input dataframe\")\n",
    "    parser.add_argument(\"--labels\", type=str, help=\"path to ordered list of labels\")\n",
    "    parser.add_argument(\n",
    "        \"--tfidf_scores\", type=str, help=\"path to tfidf scores for data\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--feature_names\", type=str, help=\"path to ordered list of feature names\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "\n",
    "    print(\"input data:\", args.data)\n",
    "\n",
    "    df = pd.read_csv(args.data, sep=\"\\t\")\n",
    "\n",
    "    word_features, labels = get_features_and_labels(df)\n",
    "    tfidf_scores, feature_names = get_tfidf_and_names(word_features)\n",
    "\n",
    "    print(f\"labels: {args.labels}\")\n",
    "    print(f\"feature_names: {args.feature_names}\")\n",
    "    print(f\"tfidf_scores: {args.tfidf_scores}\")\n",
    "\n",
    "    np.save(os.path.join(args.labels, \"labels.npy\"), labels)\n",
    "    np.save(os.path.join(args.feature_names, \"feature_names.npy\"), feature_names)\n",
    "    save_npz(os.path.join(args.tfidf_scores, \"tfidf_scores.npz\"), tfidf_scores)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "data_prep_component = command(\n",
    "    name=\"data_prepocessing_for_classifier_workbench\",\n",
    "    display_name=\"Data preprocessing for eppi classifier workbench\",\n",
    "    description=\"Tokenizes and processes text data using spaCy then generates tfirf\",\n",
    "    inputs={\n",
    "        \"data\": Input(type=\"uri_file\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"labels\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        \"feature_names\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        \"tfidf_scores\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=process_data,\n",
    "    command=\"\"\"python data_prep.py \\\n",
    "            --data ${{inputs.data}} \\\n",
    "            --labels ${{outputs.labels}} \\\n",
    "            --tfidf_scores ${{outputs.tfidf_scores}} \\\n",
    "            --feature_names ${{outputs.feature_names}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component data_prepocessing_for_classifier_workbench with Version 2024-09-19-08-41-39-5264346 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "data_prep_component = ml_client.create_or_update(data_prep_component.component)\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {data_prep_component.name} with Version {data_prep_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Parameters Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "\n",
    "data_path = \"user_inputs/hyperparam_search_input.json\"\n",
    "\n",
    "search_params = Data(\n",
    "    name=\"hyperparameter_search_parameter_placeholder\",\n",
    "    path=data_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=(\n",
    "        \"Place holder for the hyperparameter search parameters for eppi classifier\"\n",
    "        \" workbench\"\n",
    "    ),\n",
    "    version=\"1.0.0\",\n",
    ")\n",
    "\n",
    "search_params = ml_client.data.create_or_update(search_params)\n",
    "print(\n",
    "    f\"Dataset with name {search_params.name} was registered to workspace, the dataset version is {search_params.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER SEARCH COMPONENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "hyperparameter_search = \"./components/hyperparameter_search\"\n",
    "os.makedirs(hyperparameter_search, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/hyperparameter_search/optuna_search.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {hyperparameter_search}/optuna_search.py\n",
    "import argparse\n",
    "import os\n",
    "from dataclasses import asdict\n",
    "\n",
    "import json\n",
    "import jsonpickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import load_npz\n",
    "import time\n",
    "from eppi_text_classification import OptunaHyperparameterOptimisation\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--labels\",\n",
    "        type=str,\n",
    "        help=\"path to ordered list of labels\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--tfidf_scores\",\n",
    "        type=str,\n",
    "        help=\"path to tfidf scores for data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--search_parameters\",\n",
    "        type=str,\n",
    "        help=\"path to search parameters for the optuna search\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--best_params\",\n",
    "        type=str,\n",
    "        help=\"path to best hypereparameters found by the search\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--search_db\",\n",
    "        type=str,\n",
    "        help=\"path to optuna search database\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    tfidf_scores = load_npz(os.path.join(args.tfidf_scores, \"tfidf_scores.npz\"))\n",
    "    labels = np.load(os.path.join(args.labels, \"labels.npy\"))\n",
    "    with open(args.search_parameters, \"r\") as file:\n",
    "        json_search_parameters = file.read()\n",
    "    kwargs = jsonpickle.decode(json_search_parameters)\n",
    "\n",
    "    optuna_db_path = os.path.join(args.search_db, \"optuna.db\")\n",
    "    print(f\"optuna_db_path: {optuna_db_path}\")\n",
    "\n",
    "    # with open(\"/mnt/optuna.db\", 'w') as f:\n",
    "    #     pass\n",
    "\n",
    "    model_name = kwargs[\"model_name\"]\n",
    "    num_trials_per_job = kwargs[\"num_trials_per_job\"]\n",
    "    n_folds = 3 if \"n_folds\" not in kwargs else kwargs[\"n_folds\"]\n",
    "    num_cv_repeats = 1 if \"num_cv_repeats\" not in kwargs else kwargs[\"num_cv_repeats\"]\n",
    "    print(f\"model_name: {model_name}\")\n",
    "    print(f\"num_trials_per_job: {num_trials_per_job}\")\n",
    "    print(f\"n_folds: {n_folds}\")\n",
    "    print(f\"num_cv_repeats: {num_cv_repeats}\")\n",
    "\n",
    "    # Perform the search\n",
    "    optimiser = OptunaHyperparameterOptimisation(\n",
    "        tfidf_scores,\n",
    "        labels,\n",
    "        model_name,\n",
    "        n_trials_per_job=num_trials_per_job,\n",
    "        n_jobs=-1,\n",
    "        nfolds=n_folds,\n",
    "        num_cv_repeats=num_cv_repeats,\n",
    "        # db_url=f\"sqlite:////mnt/optuna.db\", #Use this one on Azure\n",
    "        # db_url=None,\n",
    "        db_url=f\"sqlite:///{optuna_db_path}\",\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    best_params = optimiser.optimise_hyperparameters(study_name=\"hyperparam_search\")\n",
    "    print(f\"Time taken: {time.time() - start}\")\n",
    "\n",
    "    # Save the best parameters\n",
    "    best_params[\"model_name\"] = model_name\n",
    "    best_params = jsonpickle.encode(best_params, keys=True)\n",
    "    best_param_path = os.path.join(args.best_params, \"model_params.json\")\n",
    "    with open(best_param_path, \"w\") as f:\n",
    "        json.dump(best_params, f)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "hyperparameter_search_component = command(\n",
    "    name=\"hyperparameter_search_for_classifier_workbench\",\n",
    "    display_name=\"Hyperparameter search for eppi classifier workbench\",\n",
    "    description=(\n",
    "        \"Uses parallel optuna to search for best hyperparameters for a given \"\n",
    "        \"model, storing the history on a sqlite database\"\n",
    "    ),\n",
    "    inputs={\n",
    "        \"labels\": Input(type=\"uri_folder\"),\n",
    "        \"tfidf_scores\": Input(type=\"uri_folder\"),\n",
    "        \"search_parameters\": Input(type=\"uri_file\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"best_params\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        \"search_db\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=hyperparameter_search,\n",
    "    command=\"\"\"python optuna_search.py \\\n",
    "            --labels ${{inputs.labels}} \\\n",
    "            --tfidf_scores ${{inputs.tfidf_scores}} \\\n",
    "            --search_parameters ${{inputs.search_parameters}} \\\n",
    "            --best_params ${{outputs.best_params}} \\\n",
    "            --search_db ${{outputs.search_db}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading hyperparameter_search (0.0 MBs): 100%|██████████| 2817/2817 [00:00<00:00, 66313.57it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component hyperparameter_search_for_classifier_workbench with Version 2024-09-19-09-50-22-9031301 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "hyperparameter_search_component = ml_client.create_or_update(\n",
    "    hyperparameter_search_component.component\n",
    ")\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {hyperparameter_search_component .name} with Version {hyperparameter_search_component .version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParamSearch Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"model_name\": \"LGBMClassifier\",\n",
    "    \"num_trials_per_job\": 3,\n",
    "    \"n_folds\": 3,\n",
    "    \"num_cv_repeats\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonpickle\n",
    "import json\n",
    "\n",
    "hyperparam_search_input = {\n",
    "    \"model_name\": \"LGBMClassifier\",\n",
    "    \"num_trials_per_job\": 3,\n",
    "    \"n_folds\": 3,\n",
    "    \"num_cv_repeats\": 1,\n",
    "}\n",
    "\n",
    "serialized_input = jsonpickle.encode(hyperparam_search_input, keys=True)\n",
    "\n",
    "with open(\"user_inputs/hyperparam_search_input.json\", \"w\") as file:\n",
    "    file.write(serialized_input)\n",
    "    # json.dump(hyperparam_search_input, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "\n",
    "data_path = \"../data/raw/debunking_review.tsv\"\n",
    "\n",
    "debunking_data = Data(\n",
    "    name=\"debunking_review_data\",\n",
    "    path=data_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"Dataset for testing sams text classification pipeline\",\n",
    "    version=\"1.0.0\",\n",
    ")\n",
    "debunking_data = ml_client.data.create_or_update(debunking_data)\n",
    "print(\n",
    "    f\"Dataset with name {debunking_data.name} was registered to workspace, the dataset version is {debunking_data.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test size data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"user_inputs/test_size_025.json\", \"w\") as file:\n",
    "    json.dump(\"0.25\", file)\n",
    "with open(\"user_inputs/test_size_05.json\", \"w\") as file:\n",
    "    json.dump(\"0.5\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"user_inputs/float_1.json\", \"w\") as file:\n",
    "    json.dump(\"1\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading float_1.json\u001b[32m (< 1 MB): 100%|██████████| 3.00/3.00 [00:00<00:00, 120B/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with name user_input_float_1 was registered to workspace, the dataset version is 1.0.0\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "\n",
    "data_path = \"user_inputs/float_1.json\"\n",
    "\n",
    "user_input_float = Data(\n",
    "    name=\"user_input_float_1\",\n",
    "    path=data_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"A placeholder for user input of float 1\",\n",
    "    version=\"1.0.0\",\n",
    ")\n",
    "user_input_float = ml_client.data.create_or_update(user_input_float)\n",
    "print(\n",
    "    f\"Dataset with name {user_input_float.name} was registered to workspace, the dataset version is {user_input_float.version}\"\n",
    ")\n",
    "\n",
    "# data_path = \"user_inputs/test_size_05.json\"\n",
    "\n",
    "# test_size = Data(\n",
    "#     name=\"user_input_test_size_05\",\n",
    "#     path=data_path,\n",
    "#     type=AssetTypes.URI_FILE,\n",
    "#     description=\"A placeholder for user input for the test size\",\n",
    "#     version=\"1.0.0\",\n",
    "# )\n",
    "# test_size = ml_client.data.create_or_update(test_size)\n",
    "# print(\n",
    "#     f\"Dataset with name {test_size.name} was registered to workspace, the dataset version is {test_size.version}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "split_data = \"./components/split_data\"\n",
    "os.makedirs(split_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/split_data/split_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {split_data}/split_data.py\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import jsonpickle\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz, save_npz\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def main():\n",
    "    # input and output arguments\n",
    "    print(\"before parse\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--labels\",\n",
    "        type=str,\n",
    "        help=\"path to ordered list of labels\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--tfidf_scores\",\n",
    "        type=str,\n",
    "        help=\"path to tfidf scores for data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test_size\",\n",
    "        type=str,\n",
    "        help=\"path to the test size as a proportion of the data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--X_train\",\n",
    "        type=str,\n",
    "        help=\"path to X_train\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--X_test\",\n",
    "        type=str,\n",
    "        help=\"path to X_test\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y_train\",\n",
    "        type=str,\n",
    "        help=\"path to y_train\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y_test\",\n",
    "        type=str,\n",
    "        help=\"path to y_test\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    tfidf_scores = load_npz(os.path.join(args.tfidf_scores, \"tfidf_scores.npz\"))\n",
    "    labels = np.load(os.path.join(args.labels, \"labels.npy\"))\n",
    "    with open(args.test_size, \"r\") as file:\n",
    "        test_size = float(json.load(file))\n",
    "\n",
    "    print(f\"test_size: {test_size}\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        tfidf_scores, labels, test_size=test_size, stratify=labels, random_state=8\n",
    "    )\n",
    "\n",
    "    save_npz(os.path.join(args.X_train, \"X_train.npz\"), X_train)\n",
    "    save_npz(os.path.join(args.X_test, \"X_test.npz\"), X_test)\n",
    "    np.save(os.path.join(args.y_train, \"y_train.npy\"), y_train)\n",
    "    np.save(os.path.join(args.y_test, \"y_test.npy\"), y_test)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "split_data_component = command(\n",
    "    name=\"split_data_for_classifier_workbench\",\n",
    "    display_name=\"Split data into two sets\",\n",
    "    description=(\n",
    "        \"Uses train_test_split to split the data into two sets, storing the split data\"\n",
    "    ),\n",
    "    inputs={\n",
    "        \"labels\": Input(type=\"uri_folder\"),\n",
    "        \"tfidf_scores\": Input(type=\"uri_folder\"),\n",
    "        \"test_size\": Input(type=\"uri_file\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"X_train\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        \"X_test\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        \"y_train\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        \"y_test\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=split_data,\n",
    "    command=\"\"\"python split_data.py \\\n",
    "            --labels ${{inputs.labels}} \\\n",
    "            --tfidf_scores ${{inputs.tfidf_scores}} \\\n",
    "            --test_size ${{inputs.test_size}} \\\n",
    "            --X_train ${{outputs.X_train}} \\\n",
    "            --X_test ${{outputs.X_test}} \\\n",
    "            --y_train ${{outputs.y_train}} \\\n",
    "            --y_test ${{outputs.y_test}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component split_data_for_classifier_workbench with Version 2024-09-19-08-42-09-3319537 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "split_data_component = ml_client.create_or_update(split_data_component.component)\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {split_data_component.name} with Version {split_data_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_model = \"./components/train_model\"\n",
    "os.makedirs(train_model, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/train_model/train_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {train_model}/train_model.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import json\n",
    "import jsonpickle\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "mname_to_mclass = {\n",
    "    \"SVC\": SVC,\n",
    "    \"LGBMClassifier\": LGBMClassifier,\n",
    "    \"RandomForestClassifier\": RandomForestClassifier,\n",
    "    \"XGBClassifier\": XGBClassifier,\n",
    "}\n",
    "\n",
    "\n",
    "def main():\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--X_train\",\n",
    "        type=str,\n",
    "        help=\"path to training data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y_train\",\n",
    "        type=str,\n",
    "        help=\"path to training labels\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_parameters\",\n",
    "        type=str,\n",
    "        help=\"path to model training parameters\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        type=str,\n",
    "        help=\"path to trained model\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    X_train = load_npz(os.path.join(args.X_train, \"X_train.npz\"))\n",
    "    y_train = np.load(os.path.join(args.y_train, \"y_train.npy\"))\n",
    "    model_params_path = os.path.join(args.model_parameters, \"model_params.json\")\n",
    "    with open(model_params_path, \"r\") as file:\n",
    "        json_model_parameters = json.load(file)\n",
    "    model_parameters = jsonpickle.decode(json_model_parameters)\n",
    "\n",
    "    model_class = mname_to_mclass[model_parameters.pop(\"model_name\")]\n",
    "    model = model_class(**model_parameters)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    joblib.dump(model, os.path.join(args.model, \"model.joblib\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "train_model_component = command(\n",
    "    name=\"fit_model_for_classifier_workbench\",\n",
    "    display_name=\"fit_model_for_classifier_workbench\",\n",
    "    description=(\n",
    "        \"Trains a model for classifier workbench using given data and model parameters\"\n",
    "    ),\n",
    "    inputs={\n",
    "        \"X_train\": Input(type=\"uri_folder\"),\n",
    "        \"y_train\": Input(type=\"uri_folder\"),\n",
    "        \"model_parameters\": Input(type=\"uri_file\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"model\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=train_model,\n",
    "    command=\"\"\"python train_model.py \\\n",
    "            --X_train ${{inputs.X_train}} \\\n",
    "            --y_train ${{inputs.y_train}} \\\n",
    "            --model_parameters ${{inputs.model_parameters}} \\\n",
    "            --model ${{outputs.model}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component fit_model_for_classifier_workbench with Version 2024-09-19-12-09-40-4125287 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "train_model_component = ml_client.create_or_update(train_model_component.component)\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {train_model_component.name} with Version {train_model_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Scores component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "predict_scores = \"./components/predict_scores\"\n",
    "os.makedirs(predict_scores, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/predict_scores/predict_scores.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {predict_scores}/predict_scores.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from eppi_text_classification import predict_scores\n",
    "from eppi_text_classification.utils import (\n",
    "    load_csr_at_directory,\n",
    "    load_joblib_model_at_directory,\n",
    ")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--X\",\n",
    "        type=str,\n",
    "        help=\"path to prediction data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y_pred_probs\",\n",
    "        type=str,\n",
    "        help=\"path to the predicted probabilities\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        type=str,\n",
    "        help=\"path to trained model\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    X = load_csr_at_directory(args.X)\n",
    "    model = load_joblib_model_at_directory(args.model)\n",
    "\n",
    "    y_pred_probabilities = predict_scores(model, X)\n",
    "\n",
    "    np.save(os.path.join(args.y_pred_probs, \"y_pred_probs.npy\"), y_pred_probabilities)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "predict_probabilities_component = command(\n",
    "    name=\"predict_probabilities_for_eppi_classifier_workbench\",\n",
    "    display_name=\"predict_probabilities_for_eppi_classifier_workbench\",\n",
    "    description=(\n",
    "        \"Takes a model from the eppi classifier workbench and uses it to predict \"\n",
    "        \"probabilities\"\n",
    "    ),\n",
    "    inputs={\n",
    "        \"X\": Input(type=\"uri_folder\"),\n",
    "        \"model\": Input(type=\"uri_folder\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"y_pred_probs\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=predict_scores,\n",
    "    command=\"\"\"python predict_scores.py \\\n",
    "            --X ${{inputs.X}} \\\n",
    "            --model ${{inputs.model}} \\\n",
    "            --y_pred_probs ${{outputs.y_pred_probs}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading predict_scores (0.0 MBs): 100%|██████████| 939/939 [00:00<00:00, 48449.40it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component predict_probabilities_for_eppi_classifier_workbench with Version 2024-09-19-13-09-53-6822957 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "predict_probabilities_component = ml_client.create_or_update(\n",
    "    predict_probabilities_component.component\n",
    ")\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {predict_probabilities_component.name} with Version {predict_probabilities_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly ROC component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "plotly_roc = \"./components/plotly_roc\"\n",
    "os.makedirs(plotly_roc, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/plotly_roc/plotly_roc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {plotly_roc}/plotly_roc.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from eppi_text_classification import plotly_roc\n",
    "from eppi_text_classification.utils import load_np_array_at_directory\n",
    "\n",
    "\n",
    "def main():\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--y\",\n",
    "        type=str,\n",
    "        help=\"path to labels\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y_pred_probs\",\n",
    "        type=str,\n",
    "        help=\"path to the predicted probabilities\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--roc_plot\",\n",
    "        type=str,\n",
    "        help=\"path to the roc plot\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    y = load_np_array_at_directory(args.y)\n",
    "    y_pred_probs = load_np_array_at_directory(args.y_pred_probs)\n",
    "\n",
    "    roc_plot_path = Path(args.roc_plot) / \"roc_plot.html\"\n",
    "    plotly_roc(y, y_pred_probs, save_path=roc_plot_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "plotly_roc_component = command(\n",
    "    name=\"roc_plot_for_eppi_classifier_workbench\",\n",
    "    display_name=\"ROC plot for eppi classifier workbench\",\n",
    "    description=(\"Plots ROC curve for given labels and predicted probabilities\"),\n",
    "    inputs={\n",
    "        \"y\": Input(type=\"uri_folder\"),\n",
    "        \"y_pred_probs\": Input(type=\"uri_folder\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"roc_plot\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=plotly_roc,\n",
    "    command=\"\"\"python plotly_roc.py \\\n",
    "            --y ${{inputs.y}} \\\n",
    "            --y_pred_probs ${{inputs.y_pred_probs}} \\\n",
    "            --roc_plot ${{outputs.roc_plot}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading plotly_roc (0.0 MBs): 100%|██████████| 882/882 [00:00<00:00, 30044.72it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component roc_plot_for_eppi_classifier_workbench with Version 1 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "plotly_roc_component = ml_client.create_or_update(plotly_roc_component.component)\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {plotly_roc_component.name} with Version {plotly_roc_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View HTML image component\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "view_html_image = \"./components/view_html_image\"\n",
    "os.makedirs(view_html_image, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/view_html_image/view_html_image.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {view_html_image}/view_html_image.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def main():\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--image\",\n",
    "        type=str,\n",
    "        help=\"path to image\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    image_path = os.path.join(args.image, os.listdir(args.image)[0])\n",
    "\n",
    "    mlflow.log_artifact(image_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "view_html_image_component = command(\n",
    "    name=\"view_html_image\",\n",
    "    display_name=\"Display image from html file in logs\",\n",
    "    description=(\"Display image from html file in logs\"),\n",
    "    inputs={\n",
    "        \"image\": Input(type=\"uri_folder\"),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=view_html_image,\n",
    "    command=\"\"\"python view_html_image.py \\\n",
    "            --image ${{inputs.image}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{display_image_env.name}:{display_image_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component view_html_image with Version 2024-09-19-14-53-48-5180406 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "view_html_image_component = ml_client.create_or_update(\n",
    "    view_html_image_component.component\n",
    ")\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {view_html_image_component.name} with Version {view_html_image_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get raw threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "get_threshold = \"./components/get_threshold\"\n",
    "os.makedirs(get_threshold, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/get_threshold/get_threshold.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {get_threshold}/get_threshold.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from eppi_text_classification import get_raw_threshold\n",
    "from eppi_text_classification.utils import (\n",
    "    load_csr_at_directory,\n",
    "    load_joblib_model_at_directory,\n",
    "    load_np_array_at_directory,\n",
    ")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--X\",\n",
    "        type=str,\n",
    "        help=\"path to X data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y\",\n",
    "        type=str,\n",
    "        help=\"path to y data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        type=str,\n",
    "        help=\"path to model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--target_tpr\",\n",
    "        type=str,\n",
    "        help=\"path to target true positive rate\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--threshold\",\n",
    "        type=str,\n",
    "        help=\"path to threshold\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    model = load_joblib_model_at_directory(args.model)\n",
    "    X = load_csr_at_directory(args.X)\n",
    "    y = load_np_array_at_directory(args.y)\n",
    "    with open(args.target_tpr) as file:\n",
    "        target_tpr = float(json.load(file))\n",
    "\n",
    "    threshold = get_raw_threshold(model, X, y, target_tpr)\n",
    "\n",
    "    print(f\"threshold: {threshold}\")\n",
    "    with open(os.path.join(args.threshold, \"threshold.json\"), \"w\") as file:\n",
    "        json.dump(threshold, file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "get_threshold_component = command(\n",
    "    name=\"get_classification_threshold_for_classifier_workbench\",\n",
    "    display_name=\"Get the classification threshold for a given TPR\",\n",
    "    description=(\n",
    "        \"For a given desired true positive rate, get the classification threshold\"\n",
    "    ),\n",
    "    inputs={\n",
    "        \"y\": Input(type=\"uri_folder\"),\n",
    "        \"X\": Input(type=\"uri_folder\"),\n",
    "        \"model\": Input(type=\"uri_folder\"),\n",
    "        \"target_tpr\": Input(type=\"uri_folder\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"threshold\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=get_threshold,\n",
    "    command=\"\"\"python get_threshold.py \\\n",
    "            --y ${{inputs.y}} \\\n",
    "            --X ${{inputs.X}} \\\n",
    "            --model ${{inputs.model}} \\\n",
    "            --target_tpr ${{inputs.target_tpr}} \\\n",
    "            --threshold ${{outputs.threshold}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading get_threshold (0.0 MBs): 100%|██████████| 1341/1341 [00:00<00:00, 41354.33it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component get_classification_threshold_for_classifier_workbench with Version 2024-09-19-16-14-31-9634317 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "get_threshold_component = ml_client.create_or_update(get_threshold_component.component)\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {get_threshold_component.name} with Version {get_threshold_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Predict component\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "threshold_predict = \"./components/threshold_predict\"\n",
    "os.makedirs(threshold_predict, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/threshold_predict/threshold_predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {threshold_predict}/threshold_predict.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from eppi_text_classification import raw_threshold_predict\n",
    "from eppi_text_classification.utils import (\n",
    "    load_csr_at_directory,\n",
    "    load_joblib_model_at_directory,\n",
    "    load_np_array_at_directory,\n",
    "    load_value_from_json_at_directory,\n",
    ")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--X\",\n",
    "        type=str,\n",
    "        help=\"path to X data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        type=str,\n",
    "        help=\"path to model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--threshold\",\n",
    "        type=str,\n",
    "        help=\"path to threshold\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y_pred\",\n",
    "        type=str,\n",
    "        help=\"path to y predictions\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    model = load_joblib_model_at_directory(args.model)\n",
    "    X = load_csr_at_directory(args.X)\n",
    "    threshold = float(load_value_from_json_at_directory(args.threshold))\n",
    "\n",
    "    y_pred = raw_threshold_predict(model, X, threshold)\n",
    "\n",
    "    np.save(os.path.join(args.y_pred, \"y_pred.npy\"), y_pred)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "threshold_predict = command(\n",
    "    name=\"predict_given_threshold_for_classifier_workbench\",\n",
    "    display_name=\"Predict given a threshold for classifier workbench model\",\n",
    "    description=(\"Predict given a threshold for classifier workbench model\"),\n",
    "    inputs={\n",
    "        \"X\": Input(type=\"uri_folder\"),\n",
    "        \"model\": Input(type=\"uri_folder\"),\n",
    "        \"threshold\": Input(type=\"uri_folder\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"y_pred\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=threshold_predict,\n",
    "    command=\"\"\"python threshold_predict.py \\\n",
    "            --X ${{inputs.X}} \\\n",
    "            --model ${{inputs.model}} \\\n",
    "            --threshold ${{inputs.threshold}} \\\n",
    "            --y_pred ${{outputs.y_pred}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component predict_given_threshold_for_classifier_workbench with Version 2024-09-19-17-29-28-1618210 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "threshold_predict = ml_client.create_or_update(threshold_predict.component)\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {threshold_predict.name} with Version {threshold_predict.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly confusion plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "plotly_confusion = \"./components/plotly_confusion\"\n",
    "os.makedirs(plotly_confusion, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/plotly_confusion/plotly_confusion.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {plotly_confusion}/plotly_confusion.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from eppi_text_classification import (\n",
    "    binary_train_valid_confusion_plotly,\n",
    "    binary_train_valid_test_confusion_plotly,\n",
    ")\n",
    "from eppi_text_classification.utils import load_np_array_at_directory\n",
    "\n",
    "\n",
    "def main():\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--y_train\",\n",
    "        type=str,\n",
    "        help=\"path to y_train\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y_train_pred\",\n",
    "        type=str,\n",
    "        help=\"path to y_train_pred\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y_val\",\n",
    "        type=str,\n",
    "        help=\"path to y_val\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y_val_pred\",\n",
    "        type=str,\n",
    "        help=\"path to y_val_pred\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y_test\",\n",
    "        type=str,\n",
    "        help=\"path to y_test\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--y_test_pred\",\n",
    "        type=str,\n",
    "        help=\"path to y_test_pred\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--confusion_plot\",\n",
    "        type=str,\n",
    "        help=\"path to confusion plot\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    y_train = load_np_array_at_directory(args.y_train)\n",
    "    y_train_pred = load_np_array_at_directory(args.y_train_pred)\n",
    "    y_val = load_np_array_at_directory(args.y_val)\n",
    "    y_val_pred = load_np_array_at_directory(args.y_val_pred)\n",
    "    y_test = load_np_array_at_directory(args.y_test)\n",
    "    y_test_pred = load_np_array_at_directory(args.y_test_pred)\n",
    "\n",
    "    save_path = Path(args.confusion_plot) / \"confusion_plot.html\"\n",
    "\n",
    "    if not args.y_test:\n",
    "        binary_train_valid_confusion_plotly(\n",
    "            y_train,\n",
    "            y_train_pred,\n",
    "            y_val,\n",
    "            y_val_pred,\n",
    "            postive_label=\"Included\",\n",
    "            negative_label=\"Excluded\",\n",
    "            save_path=save_path,\n",
    "        )\n",
    "    else:\n",
    "        binary_train_valid_test_confusion_plotly(\n",
    "            y_train,\n",
    "            y_train_pred,\n",
    "            y_val,\n",
    "            y_val_pred,\n",
    "            y_test,\n",
    "            y_test_pred,\n",
    "            postive_label=\"Included\",\n",
    "            negative_label=\"Excluded\",\n",
    "            save_path=save_path,\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "plotly_confusion_component = command(\n",
    "    name=\"confusion_plot_for_classifier_workbench\",\n",
    "    display_name=\"Confusion Matrix Plot\",\n",
    "    description=(\n",
    "        \"Confusion matrix that plots three or two confusion plots based on whether\"\n",
    "        \"test data is provided\"\n",
    "    ),\n",
    "    inputs={\n",
    "        \"y_train\": Input(type=\"uri_folder\"),\n",
    "        \"y_train_pred\": Input(type=\"uri_folder\"),\n",
    "        \"y_val\": Input(type=\"uri_folder\"),\n",
    "        \"y_val_pred\": Input(type=\"uri_folder\"),\n",
    "        \"y_test\": Input(type=\"uri_folder\", optional=True),\n",
    "        \"y_test_pred\": Input(type=\"uri_folder\", optional=True),\n",
    "    },\n",
    "    outputs={\n",
    "        \"confusion_plot\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=plotly_confusion,\n",
    "    command=\"\"\"python plotly_confusion.py \\\n",
    "            --y_train ${{inputs.y_train}} \\\n",
    "            --y_train_pred ${{inputs.y_train_pred}} \\\n",
    "            --y_val ${{inputs.y_val}} \\\n",
    "            --y_val_pred ${{inputs.y_val_pred}} \\\n",
    "            $[[--y_test ${{inputs.y_test}}]] \\\n",
    "            $[[--y_test_pred ${{inputs.y_test_pred}}]] \\\n",
    "            --confusion_plot ${{outputs.confusion_plot}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component confusion_plot_for_classifier_workbench with Version 2024-09-19-17-47-20-7625953 is registered\n"
     ]
    }
   ],
   "source": [
    "# Now we register the component to the workspace\n",
    "plotly_confusion_component = ml_client.create_or_update(\n",
    "    plotly_confusion_component.component\n",
    ")\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {plotly_confusion_component.name} with Version {plotly_confusion_component.version} is registered\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
